{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "executionInfo": {
     "elapsed": 865,
     "status": "ok",
     "timestamp": 1607441673747,
     "user": {
      "displayName": "JC",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GhZsM8Nv6tDysYR5PaB5v9OjgczpKmmkgBEHXd3Hg=s64",
      "userId": "15668478711161084067"
     },
     "user_tz": 300
    },
    "id": "NzZmnLmW1FwO"
   },
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import time\n",
    "import argparse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "id": "2EGucT3O1Qn7"
   },
   "outputs": [],
   "source": [
    "def find_mid_points(box):\n",
    "    # box = [x_left_top, y_left_top, width, height]\n",
    "    x = box[0] + box[2] * 0.5\n",
    "    y = box[1] + box[3]\n",
    "    coor = np.array([[[int(x), int(y)]]], dtype = \"float32\")\n",
    "    return coor\n",
    "\n",
    "# Function to calculate bottom center for all bounding boxes and transform prespective for all points.\n",
    "def get_transformed_points(boxes, transformation_matrix):\n",
    "    \n",
    "    image_pixels = []\n",
    "    for box in boxes:\n",
    "        coor = find_mid_points(box)\n",
    "        #pnts = np.array([[[int(box[0]+(box[2]*0.5)),int(box[1]+(box[3]*0.5))]]] , dtype=\"float32\")\n",
    "        new_coor = cv2.perspectiveTransform(coor, transformation_matrix)[0][0]\n",
    "        image_pixel = [int(new_coor[0]), int(new_coor[1])]\n",
    "        image_pixels.append(image_pixel)\n",
    "        \n",
    "    return image_pixels\n",
    "\n",
    "# Function calculates distance between two points(humans). distance_w, distance_h represents number\n",
    "# of pixels in 180cm length horizontally and vertically. We calculate horizontal and vertical\n",
    "# distance in pixels for two points and get ratio in terms of 180 cm distance using distance_w, distance_h.\n",
    "# Then we calculate how much cm distance is horizontally and vertically and then using pythagoras\n",
    "# we calculate distance between points in terms of cm. \n",
    "# def cal_dis(p1, p2, distance_w, distance_h):\n",
    "    \n",
    "#     h = abs(p2[1]-p1[1])\n",
    "#     w = abs(p2[0]-p1[0])\n",
    "    \n",
    "#     dis_w = float((w/distance_w)*180)\n",
    "#     dis_h = float((h/distance_h)*180)\n",
    "    \n",
    "#     return int(np.sqrt(((dis_h)**2) + ((dis_w)**2)))\n",
    "\n",
    "# Function calculates distance between all pairs and calculates closeness ratio.\n",
    "def get_distances(boxes1, image_pixels, distance_w, distance_h):\n",
    "    \n",
    "    distances_matrix = []\n",
    "    colored_boxes = []\n",
    "    low_risk = 0\n",
    "    mid_risk = 1\n",
    "    high_risk = 2\n",
    "    \n",
    "    for i in range(len(image_pixels)):\n",
    "        for j in range(len(image_pixels)):\n",
    "            if i != j:\n",
    "#                 dist = cal_dis(image_pixels[i], image_pixels[j], distance_w, distance_h)\n",
    "                distance = int(np.sqrt(((float((abs(image_pixels[i][1]-image_pixels[j][1])/distance_h)*180))**2) + ((float((abs(image_pixels[i][0]-image_pixels[j][0])/distance_w)*180))**2)))\n",
    "               \n",
    "                if distance <= 150:\n",
    "                    \n",
    "                    distances_matrix.append([image_pixels[i], image_pixels[j], low_risk])\n",
    "                    colored_boxes.append([boxes1[i], boxes1[j], low_risk])\n",
    "                elif distance > 150 and distance <=180:\n",
    "                    \n",
    "                    distances_matrix.append([image_pixels[i], image_pixels[j], mid_risk])\n",
    "                    colored_boxes.append([boxes1[i], boxes1[j], mid_risk])       \n",
    "                else:\n",
    "                    \n",
    "                    distances_matrix.append([image_pixels[i], image_pixels[j], high_risk])\n",
    "                    colored_boxes.append([boxes1[i], boxes1[j], high_risk])\n",
    "                \n",
    "    return distances_matrix, colored_boxes\n",
    " \n",
    "    \n",
    "    return float(dis_w/W),float(dis_h/H)\n",
    "    \n",
    "# Function gives count for humans at high risk, low risk and no risk    \n",
    "def get_count(distances_matrix):\n",
    "\n",
    "    r = []\n",
    "    g = []\n",
    "    y = []\n",
    "    \n",
    "    for i in range(len(distances_matrix)):\n",
    "\n",
    "        if distances_matrix[i][2] == 0:\n",
    "            if (distances_matrix[i][0] not in r) and (distances_matrix[i][0] not in g) and (distances_matrix[i][0] not in y):\n",
    "                r.append(distances_matrix[i][0])\n",
    "            if (distances_matrix[i][1] not in r) and (distances_matrix[i][1] not in g) and (distances_matrix[i][1] not in y):\n",
    "                r.append(distances_matrix[i][1])\n",
    "                \n",
    "    for i in range(len(distances_matrix)):\n",
    "\n",
    "        if distances_matrix[i][2] == 1:\n",
    "            if (distances_matrix[i][0] not in r) and (distances_matrix[i][0] not in g) and (distances_matrix[i][0] not in y):\n",
    "                y.append(distances_matrix[i][0])\n",
    "            if (distances_matrix[i][1] not in r) and (distances_matrix[i][1] not in g) and (distances_matrix[i][1] not in y):\n",
    "                y.append(distances_matrix[i][1])\n",
    "        \n",
    "    for i in range(len(distances_matrix)):\n",
    "    \n",
    "        if distances_matrix[i][2] == 2:\n",
    "            if (distances_matrix[i][0] not in r) and (distances_matrix[i][0] not in g) and (distances_matrix[i][0] not in y):\n",
    "                g.append(distances_matrix[i][0])\n",
    "            if (distances_matrix[i][1] not in r) and (distances_matrix[i][1] not in g) and (distances_matrix[i][1] not in y):\n",
    "                g.append(distances_matrix[i][1])\n",
    "   \n",
    "    return (len(r),len(y),len(g))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "id": "LZPgcsFb1R6E"
   },
   "outputs": [],
   "source": [
    "def transform_frame(frame, transformation_matrix):\n",
    "    rows, cols, _ = frame.shape\n",
    "    new_frame = cv2.warpPerspective(frame, transformation_matrix, (cols, rows))\n",
    "    scale_w =int(new_frame.shape[0] / frame.shape[0])\n",
    "    scale_h = int(new_frame.shape[1] / frame.shape[1])\n",
    "    return new_frame, scale_w, scale_h\n",
    "\n",
    "# Function to draw Bird Eye View for region of interest(ROI). Red, Yellow, Green points represents risk to human. \n",
    "# Red: High Risk\n",
    "# Yellow: Low Risk\n",
    "# Green: No Risk\n",
    "def bird_eye_view(frame, distances_matrix, bottom_points, risk_count, transformation_matrix):\n",
    "    h = frame.shape[0]\n",
    "    w = frame.shape[1]\n",
    "\n",
    "    red = (0, 0, 255)\n",
    "    green = (0, 255, 0)\n",
    "    yellow = (0, 255, 255)\n",
    "    white = (200, 200, 200)\n",
    "    \n",
    "    new_frame, scale_w, scale_h = transform_frame(frame, transformation_matrix)\n",
    "    \n",
    "#     scale_w =int(new_frame.shape[0] / frame.shape[0])\n",
    "#     scale_h = int(new_frame.shape[1] / frame.shape[1])\n",
    "    \n",
    "    \n",
    "    \n",
    "#     blank_image = np.zeros((int(h * scale_h), int(w * scale_w), 3), np.uint8)\n",
    "#     blank_image[:] = white\n",
    "#     warped_pts = []\n",
    "    r = []\n",
    "    g = []\n",
    "    y = []\n",
    "    for i in range(len(distances_matrix)):\n",
    "\n",
    "        if distances_matrix[i][2] == 0:\n",
    "            if (distances_matrix[i][0] not in r) and (distances_matrix[i][0] not in g) and (distances_matrix[i][0] not in y):\n",
    "                r.append(distances_matrix[i][0])\n",
    "            if (distances_matrix[i][1] not in r) and (distances_matrix[i][1] not in g) and (distances_matrix[i][1] not in y):\n",
    "                r.append(distances_matrix[i][1])\n",
    "\n",
    "            new_frame = cv2.line(new_frame, (int(distances_matrix[i][0][0] * scale_w), int(distances_matrix[i][0][1] * scale_h)), (int(distances_matrix[i][1][0] * scale_w), int(distances_matrix[i][1][1]* scale_h)), red, 2)\n",
    "            \n",
    "    for i in range(len(distances_matrix)):\n",
    "                \n",
    "        if distances_matrix[i][2] == 1:\n",
    "            if (distances_matrix[i][0] not in r) and (distances_matrix[i][0] not in g) and (distances_matrix[i][0] not in y):\n",
    "                y.append(distances_matrix[i][0])\n",
    "            if (distances_matrix[i][1] not in r) and (distances_matrix[i][1] not in g) and (distances_matrix[i][1] not in y):\n",
    "                y.append(distances_matrix[i][1])\n",
    "        \n",
    "            new_frame = cv2.line(new_frame, (int(distances_matrix[i][0][0] * scale_w), int(distances_matrix[i][0][1] * scale_h)), (int(distances_matrix[i][1][0] * scale_w), int(distances_matrix[i][1][1]* scale_h)), yellow, 2)\n",
    "            \n",
    "    for i in range(len(distances_matrix)):\n",
    "        \n",
    "        if distances_matrix[i][2] == 2:\n",
    "            if (distances_matrix[i][0] not in r) and (distances_matrix[i][0] not in g) and (distances_matrix[i][0] not in y):\n",
    "                g.append(distances_matrix[i][0])\n",
    "            if (distances_matrix[i][1] not in r) and (distances_matrix[i][1] not in g) and (distances_matrix[i][1] not in y):\n",
    "                g.append(distances_matrix[i][1])\n",
    "    \n",
    "    for i in bottom_points:\n",
    "        new_frame = cv2.circle(new_frame, (int(i[0]  * scale_w), int(i[1] * scale_h)), 5, green, 5)\n",
    "    for i in y:\n",
    "        new_frame = cv2.circle(new_frame, (int(i[0]  * scale_w), int(i[1] * scale_h)), 5, yellow, 5)\n",
    "    for i in r:\n",
    "        new_frame = cv2.circle(new_frame, (int(i[0]  * scale_w), int(i[1] * scale_h)), 5, red, 5)\n",
    "        \n",
    "    #pad = np.full((100,blank_image.shape[1],3), [110, 110, 100], dtype=np.uint8)\n",
    "    #cv2.putText(pad, \"-- HIGH RISK : \" + str(risk_count[0]) + \" people\", (50, 20), cv2.FONT_HERSHEY_SIMPLEX, 0.5, (0, 0, 255), 1)\n",
    "    #cv2.putText(pad, \"-- LOW RISK : \" + str(risk_count[1]) + \" people\", (50, 50), cv2.FONT_HERSHEY_SIMPLEX, 0.5, (0, 255, 255), 1)\n",
    "    #cv2.putText(pad, \"-- SAFE : \" + str(risk_count[2]) + \" people\", (50,  80), cv2.FONT_HERSHEY_SIMPLEX, 0.5, (0, 255, 0), 1)\n",
    "    #blank_image = np.vstack((blank_image,pad))   \n",
    "        \n",
    "    return new_frame\n",
    "# Function to draw bounding boxes according to risk factor for humans in a frame and draw lines between\n",
    "# boxes according to risk factor between two humans.\n",
    "# Red: High Risk\n",
    "# Yellow: Low Risk\n",
    "# Green: No Risk \n",
    "def social_distancing_view(frame, distances_matrix, boxes, risk_count):\n",
    "    \n",
    "    red = (0, 0, 255)\n",
    "    green = (0, 255, 0)\n",
    "    yellow = (0, 255, 255)\n",
    "    \n",
    "    for i in range(len(boxes)):\n",
    "\n",
    "        x,y,w,h = boxes[i][:]\n",
    "        frame = cv2.rectangle(frame,(x,y),(x+w,y+h),green,2)\n",
    "                           \n",
    "    for i in range(len(distances_matrix)):\n",
    "\n",
    "        per1 = distances_matrix[i][0]\n",
    "        per2 = distances_matrix[i][1]\n",
    "        closeness = distances_matrix[i][2]\n",
    "        \n",
    "        if closeness == 1:\n",
    "            x,y,w,h = per1[:]\n",
    "            frame = cv2.rectangle(frame,(x,y),(x+w,y+h),yellow,2)\n",
    "                \n",
    "            x1,y1,w1,h1 = per2[:]\n",
    "            frame = cv2.rectangle(frame,(x1,y1),(x1+w1,y1+h1),yellow,2)\n",
    "                \n",
    "            frame = cv2.line(frame, (int(x+w/2), int(y+h/2)), (int(x1+w1/2), int(y1+h1/2)),yellow, 2) \n",
    "            \n",
    "    for i in range(len(distances_matrix)):\n",
    "\n",
    "        per1 = distances_matrix[i][0]\n",
    "        per2 = distances_matrix[i][1]\n",
    "        closeness = distances_matrix[i][2]\n",
    "        \n",
    "        if closeness == 0:\n",
    "            x,y,w,h = per1[:]\n",
    "            frame = cv2.rectangle(frame,(x,y),(x+w,y+h),red,2)\n",
    "                \n",
    "            x1,y1,w1,h1 = per2[:]\n",
    "            frame = cv2.rectangle(frame,(x1,y1),(x1+w1,y1+h1),red,2)\n",
    "                \n",
    "            frame = cv2.line(frame, (int(x+w/2), int(y+h/2)), (int(x1+w1/2), int(y1+h1/2)),red, 2)\n",
    "            \n",
    "    pad = np.full((140,frame.shape[1],3), [110, 110, 100], dtype=np.uint8)\n",
    "    cv2.putText(pad, \"Bounding box shows the level of risk to the person.\", (50, 30),cv2.FONT_HERSHEY_SIMPLEX, 0.7, (100, 100, 0), 2)\n",
    "    cv2.putText(pad, \"-- HIGH RISK : \" + str(risk_count[0]) + \" people\", (50, 60), cv2.FONT_HERSHEY_SIMPLEX, 0.6, (0, 0, 255), 1)\n",
    "    cv2.putText(pad, \"-- LOW RISK : \" + str(risk_count[1]) + \" people\", (50, 80), cv2.FONT_HERSHEY_SIMPLEX, 0.6, (0, 255, 255), 1)\n",
    "    cv2.putText(pad, \"-- SAFE : \" + str(risk_count[2]) + \" people\", (50,  100), cv2.FONT_HERSHEY_SIMPLEX, 0.6, (0, 255, 0), 1)\n",
    "    frame = np.vstack((frame,pad))\n",
    "            \n",
    "    return frame\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "id": "bJ5JnuAh1WZj"
   },
   "outputs": [],
   "source": [
    "confid = 0.5\n",
    "thresh = 0.5\n",
    "# mouse_pts = [(26, 279), (136, 444), (609, 377), (215, 273), (169, 373), (200, 403), (201, 358), (226, 387)]\n",
    "mouse_pts = []\n",
    "\n",
    "# Function to get points for Region of Interest(ROI) and distance scale. It will take 8 points on first frame using mouse click    \n",
    "# event.First four points will define ROI where we want to moniter social distancing. Also these points should form parallel  \n",
    "# lines in real world if seen from above(birds eye view). Next 3 points will define 6 feet(unit length) distance in     \n",
    "# horizontal and vertical direction and those should form parallel lines with ROI. Unit length we can take based on choice.\n",
    "# Points should pe in pre-defined order - bottom-left, bottom-right, top-right, top-left, point 5 and 6 should form     \n",
    "# horizontal line and point 5 and 7 should form verticle line. Horizontal and vertical scale will be different. \n",
    "\n",
    "# Function will be called on mouse events                                                          \n",
    "\n",
    "def get_mouse_points(event, x, y, flags, param):\n",
    "\n",
    "    global mouse_pts\n",
    "    if event == cv2.EVENT_LBUTTONDOWN:\n",
    "        if len(mouse_pts) < 4:\n",
    "            cv2.circle(image, (x, y), 5, (0, 0, 255), 10)\n",
    "        else:\n",
    "            cv2.circle(image, (x, y), 5, (255, 0, 0), 10)\n",
    "            \n",
    "        if len(mouse_pts) >= 1 and len(mouse_pts) <= 3:\n",
    "            cv2.line(image, (x, y), (mouse_pts[len(mouse_pts)-1][0], mouse_pts[len(mouse_pts)-1][1]), (70, 70, 70), 2)\n",
    "            if len(mouse_pts) == 3:\n",
    "                cv2.line(image, (x, y), (mouse_pts[0][0], mouse_pts[0][1]), (70, 70, 70), 2)\n",
    "        \n",
    "        if \"mouse_pts\" not in globals():\n",
    "            mouse_pts = []\n",
    "        mouse_pts.append((x, y))\n",
    "#         print(\"Point detected\")\n",
    "#         print(mouse_pts)\n",
    "        \n",
    "\n",
    "\n",
    "def calculate_social_distancing(vid_path, net, output_dir, output_vid, ln1):\n",
    "   \n",
    "    points = []\n",
    "    global image\n",
    "    count = 0\n",
    "    vs = cv2.VideoCapture(vid_path)    \n",
    "\n",
    "    # Get video height, width and fps\n",
    "    height = int(vs.get(cv2.CAP_PROP_FRAME_HEIGHT))\n",
    "    width = int(vs.get(cv2.CAP_PROP_FRAME_WIDTH))\n",
    "    fps = int(vs.get(cv2.CAP_PROP_FPS))\n",
    "    \n",
    "    (success, frame) = vs.read()\n",
    "    (H, W) = frame.shape[:2]\n",
    "    \n",
    "    if count == 0:\n",
    "            while True:\n",
    "                image = frame\n",
    "                cv2.imshow(\"image\", image)\n",
    "                cv2.waitKey(1)\n",
    "                if len(mouse_pts) == 8:\n",
    "                    cv2.destroyWindow(\"image\")\n",
    "                    break\n",
    "               \n",
    "            points = mouse_pts\n",
    "    \n",
    "\n",
    "    # Using first 4 points or coordinates for perspective transformation. The region marked by these 4 points are \n",
    "    # considered ROI. This polygon shaped ROI is then warped into a rectangle which becomes the bird eye view. \n",
    "    # This bird eye view then has the property property that points are distributed uniformally horizontally and \n",
    "    # vertically(scale for horizontal and vertical direction will be different). So for bird eye view points are \n",
    "    # equally distributed, which was not case for normal view.\n",
    "    \n",
    "    src = np.float32(np.array(points[:4]))\n",
    "    dst = np.float32([[0, H], [W, H], [W, 0], [0, 0]])\n",
    "    prespective_transform = cv2.getPerspectiveTransform(src, dst)\n",
    "    new_frame, scale_w, scale_h = transform_frame(frame, prespective_transform)\n",
    "\n",
    "    fourcc = cv2.VideoWriter_fourcc(*\"XVID\")\n",
    "    output_movie = cv2.VideoWriter(\"./output_vid/distancing.avi\", fourcc, fps, (width, height+140))\n",
    "#     video_width, video_height = img.shape[1], img.shape[0]\n",
    "#     output_movie = cv2.VideoWriter(\"./output_vid/distancing.avi\", fourcc, fps, (video_width, video_height))\n",
    "    bird_movie = cv2.VideoWriter(\"./output_vid/bird_eye_view.avi\", fourcc, fps, (int(width * scale_w), int(height * scale_h)))\n",
    "        \n",
    "    \n",
    "    while True:\n",
    "\n",
    "        (success, frame) = vs.read()\n",
    "\n",
    "        if not success:\n",
    "#             print('here')\n",
    "            break\n",
    "            \n",
    "        (H, W) = frame.shape[:2]\n",
    "            \n",
    "\n",
    "        # using next 3 points for horizontal and vertical unit length(in this case 180 cm)\n",
    "        pts = np.float32(np.array([points[4:7]]))\n",
    "        warped_pt = cv2.perspectiveTransform(pts, prespective_transform)[0]\n",
    "        \n",
    "        # since bird eye view has property that all points are equidistant in horizontal and vertical direction.\n",
    "        # distance_w and distance_h will give us 180 cm distance in both horizontal and vertical directions\n",
    "        # (how many pixels will be there in 180cm length in horizontal and vertical direction of birds eye view),\n",
    "        # which we can use to calculate distance between two humans in transformed view or bird eye view\n",
    "        distance_w = np.sqrt((warped_pt[0][0] - warped_pt[1][0]) ** 2 + (warped_pt[0][1] - warped_pt[1][1]) ** 2)\n",
    "        distance_h = np.sqrt((warped_pt[0][0] - warped_pt[2][0]) ** 2 + (warped_pt[0][1] - warped_pt[2][1]) ** 2)\n",
    "        pnts = np.array(points[:4], np.int32)\n",
    "        cv2.polylines(frame, [pnts], True, (70, 70, 70), thickness=2)\n",
    "    \n",
    "    ####################################################################################\n",
    "    \n",
    "        # YOLO v3\n",
    "        blob = cv2.dnn.blobFromImage(frame, 1 / 255.0, (416, 416), swapRB=True, crop=False)\n",
    "        net.setInput(blob)\n",
    "        start = time.time()\n",
    "        layerOutputs = net.forward(ln1)\n",
    "        end = time.time()\n",
    "        boxes = []\n",
    "        confidences = []\n",
    "        classIDs = []   \n",
    "    \n",
    "        for output in layerOutputs:\n",
    "            for detection in output:\n",
    "                scores = detection[5:]\n",
    "                classID = np.argmax(scores)\n",
    "                confidence = scores[classID]\n",
    "                # detecting humans in frame\n",
    "                if classID == 0:\n",
    "\n",
    "                    if confidence > confid:\n",
    "\n",
    "                        box = detection[0:4] * np.array([W, H, W, H])\n",
    "                        (centerX, centerY, width, height) = box.astype(\"int\")\n",
    "\n",
    "                        x = int(centerX - (width / 2))\n",
    "                        y = int(centerY - (height / 2))\n",
    "\n",
    "                        boxes.append([x, y, int(width), int(height)])\n",
    "                        confidences.append(float(confidence))\n",
    "                        classIDs.append(classID)\n",
    "                    \n",
    "        idxs = cv2.dnn.NMSBoxes(boxes, confidences, confid, thresh)\n",
    "        font = cv2.FONT_HERSHEY_PLAIN\n",
    "        boxes1 = []\n",
    "        for i in range(len(boxes)):\n",
    "            if i in idxs:\n",
    "                boxes1.append(boxes[i])\n",
    "                x,y,w,h = boxes[i]\n",
    "                \n",
    "        if len(boxes1) == 0:\n",
    "            count = count + 1\n",
    "            continue\n",
    "            \n",
    "        # Here we will be using bottom center point of bounding box for all boxes and will transform all those\n",
    "        # bottom center points to bird eye view\n",
    "        person_points = get_transformed_points(boxes1, prespective_transform)\n",
    "        \n",
    "        # Here we will calculate distance between transformed points(humans)\n",
    "        distances_mat, bxs_mat = get_distances(boxes1, person_points, distance_w, distance_h)\n",
    "        risk_count = get_count(distances_mat)\n",
    "    \n",
    "        frame1 = np.copy(frame)\n",
    "        \n",
    "        # Draw bird eye view and frame with bouding boxes around humans according to risk factor    \n",
    "        bird_image = bird_eye_view(frame, distances_mat, person_points, risk_count, prespective_transform)\n",
    "        img = social_distancing_view(frame1, bxs_mat, boxes1, risk_count)\n",
    "        \n",
    "        # Show/write image and videos\n",
    "        if count != 0:\n",
    "            output_movie.write(img)\n",
    "            bird_movie.write(bird_image)\n",
    "    \n",
    "            cv2.imshow('Bird Eye View', img)\n",
    "            cv2.imwrite(output_dir+\"frame%d.jpg\" % count, img)\n",
    "            cv2.imwrite(output_dir+\"bird_eye_view/frame%d.jpg\" % count, bird_image)\n",
    "    \n",
    "        count = count + 1\n",
    "        if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "            break\n",
    "     \n",
    "    vs.release()\n",
    "    cv2.destroyAllWindows() \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "id": "oQqx0VwbKowz"
   },
   "outputs": [],
   "source": [
    "confid = 0.5\n",
    "thresh = 0.5\n",
    "# mouse_pts = [(26, 279), (136, 444), (609, 377), (215, 273), (169, 373), (200, 403), (201, 358), (226, 387)]\n",
    "mouse_pts = []\n",
    "\n",
    "# Function to get points for Region of Interest(ROI) and distance scale. It will take 8 points on first frame using mouse click    \n",
    "# event.First four points will define ROI where we want to moniter social distancing. Also these points should form parallel  \n",
    "# lines in real world if seen from above(birds eye view). Next 3 points will define 6 feet(unit length) distance in     \n",
    "# horizontal and vertical direction and those should form parallel lines with ROI. Unit length we can take based on choice.\n",
    "# Points should pe in pre-defined order - bottom-left, bottom-right, top-right, top-left, point 5 and 6 should form     \n",
    "# horizontal line and point 5 and 7 should form verticle line. Horizontal and vertical scale will be different. \n",
    "\n",
    "# Function will be called on mouse events                                                          \n",
    "\n",
    "def get_mouse_points(event, x, y, flags, param):\n",
    "\n",
    "    global mouse_pts\n",
    "    if event == cv2.EVENT_LBUTTONDOWN:\n",
    "        if len(mouse_pts) < 4: # points for ROI\n",
    "            cv2.circle(image, (x, y), 5, (0, 0, 255), 10)\n",
    "        else: # points to define 6 deet\n",
    "            cv2.circle(image, (x, y), 5, (255, 0, 0), 10)\n",
    "            \n",
    "        if len(mouse_pts) >= 1 and len(mouse_pts) <= 3:\n",
    "            cv2.line(image, (x, y), (mouse_pts[len(mouse_pts)-1][0], mouse_pts[len(mouse_pts)-1][1]), (70, 70, 70), 2)\n",
    "            if len(mouse_pts) == 3:\n",
    "                cv2.line(image, (x, y), (mouse_pts[0][0], mouse_pts[0][1]), (70, 70, 70), 2)\n",
    "        \n",
    "        if \"mouse_pts\" not in globals():\n",
    "            mouse_pts = []\n",
    "        mouse_pts.append((x, y))\n",
    "#         print(\"Point detected\")\n",
    "#         print(mouse_pts)\n",
    "        \n",
    "\n",
    "\n",
    "def calculate_social_distancing4colab(vid_path, net, output_dir, output_vid, ln1):\n",
    "    \n",
    "    points = []\n",
    "    global image\n",
    "    count = 0\n",
    "    vs = cv2.VideoCapture(vid_path)    \n",
    "\n",
    "    # Get video height, width and fps\n",
    "    height = int(vs.get(cv2.CAP_PROP_FRAME_HEIGHT))\n",
    "    width = int(vs.get(cv2.CAP_PROP_FRAME_WIDTH))\n",
    "    fps = int(vs.get(cv2.CAP_PROP_FPS))\n",
    "    \n",
    "    (success, frame) = vs.read()\n",
    "    (H, W) = frame.shape[:2]\n",
    "    \n",
    "        \n",
    "    points = mouse_pts\n",
    "    \n",
    "\n",
    "    # Using first 4 points or coordinates for perspective transformation. The region marked by these 4 points are \n",
    "    # considered ROI. This polygon shaped ROI is then warped into a rectangle which becomes the bird eye view. \n",
    "    # This bird eye view then has the property property that points are distributed uniformally horizontally and \n",
    "    # vertically(scale for horizontal and vertical direction will be different). So for bird eye view points are \n",
    "    # equally distributed, which was not case for normal view.\n",
    "    \n",
    "    src = np.float32(np.array(points[:4]))\n",
    "    dst = np.float32([[0, H], [W, H], [W, 0], [0, 0]])\n",
    "    prespective_transform = cv2.getPerspectiveTransform(src, dst)\n",
    "    new_frame, scale_w, scale_h = transform_frame(frame, prespective_transform)\n",
    "\n",
    "    fourcc = cv2.VideoWriter_fourcc(*\"XVID\")\n",
    "    output_movie = cv2.VideoWriter(\"./output_vid/distancing.avi\", fourcc, fps, (width, height+140))\n",
    "#     video_width, video_height = img.shape[1], img.shape[0]\n",
    "#     output_movie = cv2.VideoWriter(\"./output_vid/distancing.avi\", fourcc, fps, (video_width, video_height))\n",
    "    bird_movie = cv2.VideoWriter(\"./output_vid/bird_eye_view.avi\", fourcc, fps, (int(width * scale_w), int(height * scale_h)))\n",
    "        \n",
    "    \n",
    "    while True:\n",
    "\n",
    "        (success, frame) = vs.read()\n",
    "\n",
    "        if not success:\n",
    "#             print('here')\n",
    "            break\n",
    "            \n",
    "        (H, W) = frame.shape[:2]\n",
    "            \n",
    "\n",
    "        # using next 3 points for horizontal and vertical unit length(in this case 180 cm)\n",
    "        pts = np.float32(np.array([points[4:7]]))\n",
    "        warped_pt = cv2.perspectiveTransform(pts, prespective_transform)[0]\n",
    "        \n",
    "        # since bird eye view has property that all points are equidistant in horizontal and vertical direction.\n",
    "        # distance_w and distance_h will give us 180 cm distance in both horizontal and vertical directions\n",
    "        # (how many pixels will be there in 180cm length in horizontal and vertical direction of birds eye view),\n",
    "        # which we can use to calculate distance between two humans in transformed view or bird eye view\n",
    "        distance_w = np.sqrt((warped_pt[0][0] - warped_pt[1][0]) ** 2 + (warped_pt[0][1] - warped_pt[1][1]) ** 2)\n",
    "        distance_h = np.sqrt((warped_pt[0][0] - warped_pt[2][0]) ** 2 + (warped_pt[0][1] - warped_pt[2][1]) ** 2)\n",
    "        pnts = np.array(points[:4], np.int32)\n",
    "        cv2.polylines(frame, [pnts], True, (70, 70, 70), thickness=2)\n",
    "    \n",
    "    ####################################################################################\n",
    "    \n",
    "        # YOLO v3\n",
    "        blob = cv2.dnn.blobFromImage(frame, 1 / 255.0, (416, 416), swapRB=True, crop=False)\n",
    "        net.setInput(blob)\n",
    "        start = time.time()\n",
    "        layerOutputs = net.forward(ln1)\n",
    "        end = time.time()\n",
    "        boxes = []\n",
    "        confidences = []\n",
    "        classIDs = []   \n",
    "    \n",
    "        for output in layerOutputs:\n",
    "            for detection in output:\n",
    "                scores = detection[5:]\n",
    "                classID = np.argmax(scores)\n",
    "                confidence = scores[classID]\n",
    "                # detecting humans in frame\n",
    "                if classID == 0:\n",
    "\n",
    "                    if confidence > confid:\n",
    "\n",
    "                        box = detection[0:4] * np.array([W, H, W, H])\n",
    "                        (centerX, centerY, width, height) = box.astype(\"int\")\n",
    "\n",
    "                        x = int(centerX - (width / 2))\n",
    "                        y = int(centerY - (height / 2))\n",
    "\n",
    "                        boxes.append([x, y, int(width), int(height)])\n",
    "                        confidences.append(float(confidence))\n",
    "                        classIDs.append(classID)\n",
    "                    \n",
    "        idxs = cv2.dnn.NMSBoxes(boxes, confidences, confid, thresh)\n",
    "        font = cv2.FONT_HERSHEY_PLAIN\n",
    "        boxes1 = []\n",
    "        for i in range(len(boxes)):\n",
    "            if i in idxs:\n",
    "                boxes1.append(boxes[i])\n",
    "                x,y,w,h = boxes[i]\n",
    "                \n",
    "        if len(boxes1) == 0:\n",
    "            count = count + 1\n",
    "            continue\n",
    "            \n",
    "        # Here we will be using bottom center point of bounding box for all boxes and will transform all those\n",
    "        # bottom center points to bird eye view\n",
    "        person_points = get_transformed_points(boxes1, prespective_transform)\n",
    "        \n",
    "        # Here we will calculate distance between transformed points(humans)\n",
    "        distances_mat, bxs_mat = get_distances(boxes1, person_points, distance_w, distance_h)\n",
    "        risk_count = get_count(distances_mat)\n",
    "    \n",
    "        frame1 = np.copy(frame)\n",
    "        \n",
    "        # Draw bird eye view and frame with bouding boxes around humans according to risk factor    \n",
    "        bird_image = bird_eye_view(frame, distances_mat, person_points, risk_count, prespective_transform)\n",
    "        img = social_distancing_view(frame1, bxs_mat, boxes1, risk_count)\n",
    "        \n",
    "        # Show/write image and videos\n",
    "        if count != 0:\n",
    "            output_movie.write(img)\n",
    "            bird_movie.write(bird_image)\n",
    "    \n",
    "            cv2_imshow(img)\n",
    "            cv2.imwrite(output_dir+\"frame%d.jpg\" % count, img)\n",
    "            cv2.imwrite(output_dir+\"bird_eye_view/frame%d.jpg\" % count, bird_image)\n",
    "    \n",
    "        count = count + 1\n",
    "        if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "            break\n",
    "     \n",
    "    vs.release()\n",
    "    cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "id": "V7wpyM2JJNxc"
   },
   "outputs": [],
   "source": [
    "def main(output_dir = \"./output/\", output_vid = \"./output_vid/\", video_path = \"data/example2.mp4\", weightsPath = \"models/yolov3.weights\", configPath = \"models/yolov3.cfg\"):\n",
    "    \n",
    "    #     output_dir = \"./output/\"\n",
    "\n",
    "    #     output_vid = \"./output_vid/\"\n",
    "\n",
    "    #     video_path = \"data/example2.mp4\"\n",
    "    #     # load Yolov3 weights\n",
    "\n",
    "    #     weightsPath = \"models/yolov3.weights\"\n",
    "    #     configPath = \"models/yolov3.cfg\"\n",
    "    global mouse_pts\n",
    "    mouse_pts = []\n",
    "    net_yl = cv2.dnn.readNetFromDarknet(configPath, weightsPath)\n",
    "    ln = net_yl.getLayerNames()\n",
    "    ln1 = [ln[i[0] - 1] for i in net_yl.getUnconnectedOutLayers()]\n",
    "\n",
    "    # set mouse callback \n",
    "\n",
    "    cv2.namedWindow(\"image\")\n",
    "    cv2.setMouseCallback(\"image\", get_mouse_points)\n",
    "    np.random.seed(62)\n",
    "\n",
    "    calculate_social_distancing(video_path, net_yl, output_dir, output_vid, ln1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "id": "h2_CuvHUJNxd"
   },
   "outputs": [],
   "source": [
    "# for jupyter notebook\n",
    "main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "id": "JhYZ3glPJNxd"
   },
   "outputs": [],
   "source": [
    "\n",
    "main(video_path = \"data/example.mp4\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "name": "social.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
