{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "NzZmnLmW1FwO"
   },
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import time\n",
    "import argparse\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "2EGucT3O1Qn7"
   },
   "outputs": [],
   "source": [
    "class box:\n",
    "    def __init__(self, x, y, w, h):\n",
    "        self.x = x\n",
    "        self.y = y\n",
    "        self.w = w\n",
    "        self.h = h\n",
    "        self.risk = 2  # default risk level for each person is green\n",
    "\n",
    "    def set_risk(self, risk):\n",
    "        self.risk = risk\n",
    "\n",
    "    def parameters(self):\n",
    "        return self.x, self.y, self.w, self.h"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "LZPgcsFb1R6E"
   },
   "outputs": [],
   "source": [
    "def find_mid_points(box):\n",
    "    '''\n",
    "    find the bottom mid point of the box\n",
    "    :param box: the box object\n",
    "    :return: return the coordinate the bottom mid point\n",
    "    '''\n",
    "    x = box.x + box.w * 0.5\n",
    "    y = box.y + box.h\n",
    "    middle_point = np.array([[[int(x), int(y)]]], dtype=\"float32\")\n",
    "    return middle_point"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "bJ5JnuAh1WZj"
   },
   "outputs": [],
   "source": [
    "def get_transformed_points(boxes, transformation_matrix):\n",
    "    '''\n",
    "    get the transformed points\n",
    "\n",
    "    :param boxes: the list of boxes for each detected people\n",
    "    :param transformation_matrix: the transformation matrix\n",
    "    :return: the transformed point of each person\n",
    "    '''\n",
    "\n",
    "    image_pixels = []\n",
    "    for box in boxes:\n",
    "        coor = find_mid_points(box)\n",
    "        new_coor = cv2.perspectiveTransform(coor, transformation_matrix)[0][0]\n",
    "        image_pixel = [int(new_coor[0]), int(new_coor[1])]\n",
    "        image_pixels.append(image_pixel)\n",
    "\n",
    "    return image_pixels\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "id": "OCBwkAXC1gLj"
   },
   "outputs": [],
   "source": [
    "def get_distances(boxes, person_points, distance_w, distance_h):\n",
    "    \"\"\"\n",
    "    Calculates distance between all pairs, if they are close, give them risk level according to the distance\n",
    "\n",
    "    :param boxes: boxes of each recognized Pedestrian in the image\n",
    "    :param person_points: Pedestrians' coordinates after transformation\n",
    "    :param distance_w: number of pixels in 6 ft length horizontally\n",
    "    :param distance_h: number of pixels in 6 ft length vertically\n",
    "    :return: a tuple of 3.  First is all the pairs of boxes after transformation, the second is all the pairs before the\n",
    "             transformation. The last one is the set of all the boxes\n",
    "    \"\"\"\n",
    "    distance_lst = []\n",
    "    colored_pairs = []\n",
    "    colored_boxes = []\n",
    "    high_risk = 0\n",
    "    low_risk = 1\n",
    "    safe = 2\n",
    "\n",
    "    for i in range(len(person_points)):\n",
    "        for j in range(len(person_points)):\n",
    "            if i != j:\n",
    "                # calculate the euclidean distance and normalize it to 6 ft which is 180cm.\n",
    "                distance = int( 180 * np.sqrt(\n",
    "                    ((float((abs(person_points[i][1] - person_points[j][1]) / distance_h))) ** 2) + (\n",
    "                            (float((abs(person_points[i][0] - person_points[j][0]) / distance_w))) ** 2)))\n",
    "\n",
    "                if distance <= 180:\n",
    "                    risk_lvl = high_risk\n",
    "                elif 180 < distance <= 230:\n",
    "                    risk_lvl = low_risk\n",
    "                else:\n",
    "                    risk_lvl = safe\n",
    "\n",
    "                distance_lst.append([person_points[i], person_points[j], risk_lvl])\n",
    "                colored_pairs.append([boxes[i], boxes[j], risk_lvl])\n",
    "\n",
    "                # generate the set of all the boxes.\n",
    "                # Only update the risk level of a person if the current risk lvl is higher than the stored one.\n",
    "                for box in [boxes[i], boxes[j]]:\n",
    "                    if box not in colored_boxes:\n",
    "                        colored_boxes.append(box)\n",
    "                    box.set_risk(min(risk_lvl, box.risk))\n",
    "    return distance_lst, colored_pairs, colored_boxes\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def transform_frame(frame, transformation_matrix):\n",
    "    \"\"\"\n",
    "    transform the selected region to bird's eye view\n",
    "\n",
    "    :param frame: the original image\n",
    "    :param transformation_matrix: the transformation matrix\n",
    "    :return: the image after transform, width scale, and height scale\n",
    "    \"\"\"\n",
    "    rows, cols, _ = frame.shape\n",
    "    new_frame = cv2.warpPerspective(frame, transformation_matrix, (cols, rows))\n",
    "    scale_w = int(new_frame.shape[0] / frame.shape[0])\n",
    "    scale_h = int(new_frame.shape[1] / frame.shape[1])\n",
    "    return new_frame, scale_w, scale_h"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def homography(src, dst):\n",
    "    '''\n",
    "    use src and dst point to calculate a homography transformation matrix\n",
    "\n",
    "    :param src: the source points\n",
    "    :param dst: the destination points\n",
    "    :return: a transformation matrix\n",
    "    '''\n",
    "    Ax = []\n",
    "    for i in range(0, len(src)):\n",
    "        x, y = src[i][0], src[i][1]\n",
    "        u, v = dst[i][0], dst[i][1]\n",
    "        Ax.append([x, y, 1, 0, 0, 0, -u*x, -u*y, -u])\n",
    "        Ax.append([0, 0, 0, x, y, 1, -v*x, -v*y, -v])\n",
    "    Ax = np.asarray(Ax)\n",
    "    U, S, Vh = np.linalg.svd(Ax)\n",
    "    L = Vh[-1, :] / Vh[-1, -1]\n",
    "    H = L.reshape(3, 3)\n",
    "    return H"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def append_color(base_color, c1, c2, c3, i, dis_mat):\n",
    "    '''\n",
    "    Append people with different risk level to the color list.\n",
    "    '''\n",
    "\n",
    "    if dis_mat[i][0] not in c1:\n",
    "        if dis_mat[i][0] not in c2:\n",
    "            if dis_mat[i][0] not in c3:\n",
    "                base_color.append(dis_mat[i][0])\n",
    "    if dis_mat[i][1] not in c1:\n",
    "        if dis_mat[i][1] not in c2:\n",
    "            if dis_mat[i][1] not in c3:\n",
    "                base_color.append(dis_mat[i][1])\n",
    "\n",
    "    return base_color"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def bird_eye_view(frame, distances_matrix, bottom_points, transformation_matrix):\n",
    "    '''\n",
    "    Draw the Bird Eye View for region selected. Red, Yellow, Green points represents different risk levels to human.\n",
    "    Red: High Risk, Yellow: Low Risk, Green: No Risk\n",
    "    '''\n",
    "\n",
    "    h = frame.shape[0]\n",
    "    w = frame.shape[1]\n",
    "\n",
    "    color = [(0, 0, 255), (0, 255, 0), (0,165,255)]\n",
    "\n",
    "    red = color[0]\n",
    "    green = color[1]\n",
    "    orange = color[2]\n",
    "\n",
    "    new_frame, scale_w, scale_h = transform_frame(frame, transformation_matrix)\n",
    "\n",
    "    r, g, o = [], [], []\n",
    "    for i in range(len(distances_matrix)):\n",
    "\n",
    "        if distances_matrix[i][2] == 0:\n",
    "            r = append_color(r, r, g, o, i, distances_matrix)\n",
    "            new_frame = cv2.line(new_frame, (int(distances_matrix[i][0][0] * scale_w), int(distances_matrix[i][0][1] * scale_h)), (int(distances_matrix[i][1][0] * scale_w), int(distances_matrix[i][1][1] * scale_h)), red, 2)\n",
    "\n",
    "    for i in range(len(distances_matrix)):\n",
    "\n",
    "        if distances_matrix[i][2] == 1:\n",
    "            o = append_color(o, r, g, o, i, distances_matrix)\n",
    "            new_frame = cv2.line(new_frame, (int(distances_matrix[i][0][0] * scale_w), int(distances_matrix[i][0][1]* scale_h)), (int(distances_matrix[i][1][0] * scale_w), int(distances_matrix[i][1][1] * scale_h)), orange, 2)\n",
    "\n",
    "    for i in range(len(distances_matrix)):\n",
    "\n",
    "        if distances_matrix[i][2] == 2:\n",
    "            g = append_color(g, r, g, o, i, distances_matrix)\n",
    "\n",
    "    for i in g:\n",
    "        new_frame = cv2.circle(new_frame, (int(i[0]  * scale_w), int(i[1] * scale_h)), 5, green, 5)\n",
    "    for i in o:\n",
    "        new_frame = cv2.circle(new_frame, (int(i[0]  * scale_w), int(i[1] * scale_h)), 5, orange, 5)\n",
    "    for i in r:\n",
    "        new_frame = cv2.circle(new_frame, (int(i[0]  * scale_w), int(i[1] * scale_h)), 5, red, 5)\n",
    "\n",
    "    return new_frame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def social_distancing_view(frame, colored_pairs, colored_boxes):\n",
    "    '''\n",
    "    Draw the boxes and lines on the current frame\n",
    "\n",
    "    :param frame: the initial clean frame\n",
    "    :param colored_pairs: all the paris of the boxes in the form of (box1, box2, risk_level)\n",
    "    :param colored_boxes: the set of all the boxes with parameters set correctly\n",
    "    :return: the final frame with drawn boxes and lines on it\n",
    "    '''\n",
    "\n",
    "    color = [(0, 0, 255), (0, 255, 0), (0,165,255)]\n",
    "\n",
    "    red = color[0]\n",
    "    green = color[1]\n",
    "    yellow = color[2]\n",
    "\n",
    "    high_risk_count = 0\n",
    "    low_risk_count = 0\n",
    "    safe_count = 0\n",
    "\n",
    "    # Draw the box for each detected person\n",
    "    for box in colored_boxes:\n",
    "        risk_lvl = box.risk\n",
    "\n",
    "        if risk_lvl == 0:\n",
    "            sign = 'Danger'\n",
    "            color = red\n",
    "            high_risk_count += 1\n",
    "        elif risk_lvl == 1:\n",
    "            sign = 'Careful'\n",
    "            color = yellow\n",
    "            low_risk_count += 1\n",
    "        else:\n",
    "            sign = 'Safe'\n",
    "            color = green\n",
    "            safe_count += 1\n",
    "        x, y, w, h = box.parameters()\n",
    "        cv2.putText(frame, sign, (x, y - 5), cv2.FONT_HERSHEY_SIMPLEX, 0.4, color, 1)\n",
    "        frame = cv2.rectangle(frame, (x, y), (x + w, y + h), color, 2)\n",
    "\n",
    "\n",
    "    # Draw lines between boxes if the social distance is risky\n",
    "    for i in range(len(colored_pairs)):\n",
    "\n",
    "        if colored_pairs[i][2] != 2:\n",
    "            if colored_pairs[i][2] == 1:\n",
    "                color = yellow\n",
    "            else:\n",
    "                color = red\n",
    "            x1,y1,w1,h1 = colored_pairs[i][0].parameters()\n",
    "            x2,y2,w2,h2 = colored_pairs[i][1].parameters()\n",
    "\n",
    "            middle_point_x1 = int(x1+w1/2)\n",
    "            middle_point_x2 = int(x2+w2/2)\n",
    "            middle_point_y1 = int(y1+h1/2)\n",
    "            middle_point_y2 = int(y2+h2/2)\n",
    "\n",
    "            point1 = (middle_point_x1, middle_point_y1)\n",
    "            point2 = (middle_point_x2, middle_point_y2)\n",
    "\n",
    "\n",
    "            frame = cv2.line(frame, point1, point2, color, 2)\n",
    "\n",
    "    pad = np.full((138,frame.shape[1],3), [255,204,204], dtype=np.uint8)\n",
    "    font_size = 0.8\n",
    "    font_thickness = 2\n",
    "    cv2.putText(pad, \"Count of people:\", (20, 30), font, font_size, (0, 51, 102), font_thickness)\n",
    "    cv2.putText(pad, \"overly close :(\", (100, 70), font, font_size, red, font_thickness)\n",
    "    cv2.putText(pad, \"a little close :|\", (350, 70), font, font_size, yellow, font_thickness)\n",
    "    cv2.putText(pad, \"safe :)\", (600, 70), font, font_size, green, font_thickness)\n",
    "    cv2.putText(pad, str(high_risk_count), (180, 110), font, font_size, red, font_thickness)\n",
    "    cv2.putText(pad, str(low_risk_count), (430, 110), font, font_size, yellow, font_thickness)\n",
    "    cv2.putText(pad, str(safe_count) , (680, 110), font, font_size, green, font_thickness)\n",
    "    frame = np.vstack((frame,pad))\n",
    "\n",
    "    return frame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_points(frame_num, frame):\n",
    "    \n",
    "    '''\n",
    "    '''\n",
    "    \n",
    "    global image\n",
    "    p = []\n",
    "    if frame_num == 0:\n",
    "        while 1:\n",
    "            image = frame\n",
    "            cv2.imshow(\"Draw a rectangle and 3 points in real life coordinates\", image)\n",
    "            cv2.waitKey(1)\n",
    "            if len(mouse_pts) == 8:\n",
    "                cv2.destroyWindow(\"Draw a rectangle and 3 points in real life coordinates\")\n",
    "                break\n",
    "\n",
    "        p = mouse_pts\n",
    "        return p"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_video_sepc(video):\n",
    "    \n",
    "    '''\n",
    "    Read video height weight and frame rate.\n",
    "    '''\n",
    "\n",
    "    return np.array([video.get(cv2.CAP_PROP_FRAME_HEIGHT), video.get(cv2.CAP_PROP_FRAME_WIDTH), video.get(cv2.CAP_PROP_FPS)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_social_distancing(vid_path, net, output_dir, ln1):\n",
    "    '''\n",
    "    Make plot of social distance graphs and bird eye view graphs, save them and make video about it.\n",
    "    First read the original video and then extract each frame.\n",
    "    Then do the following steps: Apply Yolov3 object detection, get coordinates of each person\n",
    "    Do homography transformation to calculate transformation matrix based on the input scale.\n",
    "    Transform the frame to get bird eye view image, and transform the coordinates to calculate distances\n",
    "    Plot the distances and parameters we want to show. Finally save each frame to make videos.\n",
    "    '''\n",
    "    \n",
    "    points = []\n",
    "    \n",
    "    global font\n",
    "    font = cv2.FONT_HERSHEY_SIMPLEX\n",
    "    frame_num = 0\n",
    "    video = cv2.VideoCapture(vid_path)\n",
    "\n",
    "    # Get video height, width and fps\n",
    "    spec = get_video_sepc(video).astype(\"int\")\n",
    "    height = spec[0]\n",
    "    width = spec[1]\n",
    "    fps = spec[2]\n",
    "\n",
    "\n",
    "    (success, frame) = video.read()\n",
    "    (H, W) = frame.shape[:2]\n",
    "\n",
    "    points = get_points(frame_num, frame)\n",
    "\n",
    "\n",
    "    src = np.float32(np.array(points[:4]))\n",
    "    dst = np.float32([[0, H], [W, H], [W, 0], [0, 0]])\n",
    "    # prespective_transform, _ = cv2.findHomography(src, dst)\n",
    "    # prespective_transform = cv2.getPerspectiveTransform(src, dst)\n",
    "    prespective_transform = homography(src, dst)\n",
    "    new_frame, scale_w, scale_h = transform_frame(frame, prespective_transform)\n",
    "\n",
    "    file_name = vid_path.split('/')[-1].split('.')[0]\n",
    "    bird_eye_scale_width = int(width * scale_w)\n",
    "    bird_eye_scale_height = int(height * scale_h)\n",
    "\n",
    "    fourcc = cv2.VideoWriter_fourcc(*\"XVID\")\n",
    "    output_movie = cv2.VideoWriter(\"./output_vid/{}_distancing.avi\".format(file_name), fourcc, fps, (width, height+138))\n",
    "    bird_movie = cv2.VideoWriter(\"./output_vid/{}_bird_eye_view.avi\".format(file_name), fourcc, fps, (bird_eye_scale_width, bird_eye_scale_height))\n",
    "\n",
    "    fps_time = time.time()\n",
    "    while True:\n",
    "\n",
    "        success, frame = video.read()\n",
    "        if not success:\n",
    "            break\n",
    "\n",
    "        (H, W) = frame.shape[:2]\n",
    "\n",
    "\n",
    "        pts = np.float32(np.array([points[4:7]]))\n",
    "        warped_pt = cv2.perspectiveTransform(pts, prespective_transform)[0]\n",
    "        pt1 = warped_pt[0][0]\n",
    "        pt2 = warped_pt[1][0]\n",
    "        pt3 = warped_pt[0][1]\n",
    "        pt4 = warped_pt[1][1]\n",
    "        pt5 = warped_pt[2][0]\n",
    "        pt6 = warped_pt[2][1]\n",
    "        dis1 = pt1 - pt2\n",
    "        dis2 = pt3 - pt4\n",
    "        dis3 = pt1 - pt5\n",
    "        dis4 = pt3 - pt6\n",
    "\n",
    "        # since bird eye view has property that all points are equidistant in horizontal and vertical direction.\n",
    "        # distance_w and distance_h will give us 180 cm distance in both horizontal and vertical directions\n",
    "        # (how many pixels will be there in 180cm length in horizontal and vertical direction of birds eye view),\n",
    "        # which we can use to calculate distance between two humans in transformed view or bird eye view\n",
    "        distance_w = np.sqrt(dis1 ** 2 + dis2 ** 2)\n",
    "        distance_h = np.sqrt(dis3 ** 2 + dis4 ** 2)\n",
    "        p = points[:4]\n",
    "        p = [np.array(p)]\n",
    "        cv2.polylines(frame, p, True, (80, 80, 80), thickness=2)\n",
    "        cv2_blob = cv2.dnn.blobFromImage(frame, 1 / 255.0, (416, 416), swapRB=True, crop=False)\n",
    "        net.setInput(cv2_blob)\n",
    "        outputlayers = net.forward(ln1)\n",
    "        confidences, boxes_4_cv,  boxes= [], [], []\n",
    "\n",
    "        for output in outputlayers:\n",
    "            for detection in output:\n",
    "                confidence = detection[5]\n",
    "                if confidence > confid:\n",
    "\n",
    "                    detect_x = detection[0]\n",
    "                    detect_y = detection[1]\n",
    "                    detect_w = detection[2]\n",
    "                    detect_h = detection[3]\n",
    "\n",
    "                    scaled_detect_x = int(detect_x * W)\n",
    "                    scaled_detect_y = int(detect_y * H)\n",
    "                    scaled_detect_w = int(detect_w * W)\n",
    "                    scaled_detect_h = int(detect_h * H)\n",
    "\n",
    "                    x = int(scaled_detect_x - (scaled_detect_w / 2))\n",
    "                    y = int(scaled_detect_y - (scaled_detect_h / 2))\n",
    "\n",
    "                    boxes_4_cv.append([x, y, scaled_detect_w, scaled_detect_h])\n",
    "                    boxes.append(box(x, y, scaled_detect_w, scaled_detect_h))\n",
    "                    confidences.append(float(confidence))\n",
    "\n",
    "\n",
    "        idxs = cv2.dnn.NMSBoxes(boxes_4_cv, confidences, confid, thresh)\n",
    "\n",
    "        boxes1 = []\n",
    "        for i in range(len(boxes)):\n",
    "            if i in idxs:\n",
    "                boxes1.append(boxes[i])\n",
    "\n",
    "        if len(boxes1) == 0:\n",
    "            frame_num = frame_num + 1\n",
    "            continue\n",
    "\n",
    "        # Here we will be using bottom center point of bounding box for all boxes and will transform all those\n",
    "        # bottom center points to bird eye view\n",
    "        person_points = get_transformed_points(boxes1, prespective_transform)\n",
    "\n",
    "        # Here we will calculate distance between transformed points(humans)\n",
    "        distances_mat, colored_pairs, colored_boxes = get_distances(boxes1, person_points, distance_w, distance_h)\n",
    "        # risk_count = count_risk(distances_mat)\n",
    "\n",
    "        frame1 = np.copy(frame)\n",
    "\n",
    "        # Draw bird eye view and frame with bouding boxes around humans according to risk factor\n",
    "        bird_image = bird_eye_view(frame, distances_mat, person_points, prespective_transform)\n",
    "        img = social_distancing_view(frame1, colored_pairs, colored_boxes)\n",
    "\n",
    "        # Write Fps\n",
    "        temp = time.time()\n",
    "        img_row, img_col,_ = img.shape\n",
    "        cv2.putText(img, \"FPS: \" + str(int(1/(temp - fps_time))), (int(img_col * 0.85), int(img_row * 0.95)), font, 0.8, (255,255,255), 2)\n",
    "        fps_time = time.time()\n",
    "\n",
    "\n",
    "        # Show/write image and videos\n",
    "        if frame_num != 0:\n",
    "            output_movie.write(img)\n",
    "            bird_movie.write(bird_image)\n",
    "\n",
    "            cv2.imshow('Social distance', img)\n",
    "            img_path = output_dir + \"frame{}.jpg\".format(frame_num)\n",
    "            bird_img_path = output_dir + \"bird_eye_view/frame{}.jpg\".format(frame_num)\n",
    "            cv2.imwrite(img_path, img)\n",
    "            cv2.imwrite(bird_img_path, bird_image)\n",
    "\n",
    "        frame_num = frame_num + 1\n",
    "\n",
    "        key = cv2.waitKey(1)\n",
    "        if key == ord('x'):\n",
    "            break\n",
    "\n",
    "    video.release()\n",
    "    cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_mouse_points(e, x, y, f, p):\n",
    "    \"\"\"\n",
    "    The callback function of cv2 mouse click\n",
    "    Add all points to the global variable mouse_pts.\n",
    "    First 4 points form two parallel lines in the real world.\n",
    "    i.e. (Bottom left, Bottom right, Top right, Top left)\n",
    "    The last 3 points form two orthogonal lines in the real world.\n",
    "    Point 5 and 6 should form horizontal line and point 5 and 7 should form vertical line.\n",
    "    The length of those two lines should be the safe distance which is 6 ft.\n",
    "    \"\"\"\n",
    "    global mouse_pts\n",
    "    if e == cv2.EVENT_LBUTTONDOWN or e == cv2.EVENT_RBUTTONDOWN:\n",
    "        if len(mouse_pts) < 4:\n",
    "            # points for region selected of bird's eye view\n",
    "            cv2.circle(image, (x, y), 4, (0, 0, 255), -1)\n",
    "        else:\n",
    "            # points to define safe distance\n",
    "            cv2.circle(image, (x, y), 4, (255, 0, 0), -1)\n",
    "        # draw a line to better visualize\n",
    "        if len(mouse_pts) >= 1 and len(mouse_pts) <=3:\n",
    "            last_point = mouse_pts[-1]\n",
    "            last_point_x = last_point[0]\n",
    "            last_point_y = last_point[1]\n",
    "            first_point = mouse_pts[0]\n",
    "            first_point_x = first_point[0]\n",
    "            first_point_y = first_point[1]\n",
    "            cv2.line(image, (x, y), (last_point_x, last_point_y), (80, 80, 80), 2)\n",
    "            if len(mouse_pts) == 3:\n",
    "                cv2.line(image, (x, y), (first_point_x, first_point_y), (80, 80, 80), 2)\n",
    "\n",
    "        mouse_pts.append((x, y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def main(output_dir=\"./output/\", output_vid=\"./output_vid/\", video_path=\"data/example1.mp4\",\n",
    "         weights_path=\"models/yolov4-tiny-pedestrian_last.weights\", config_path=\"models/yolov4-tiny-pedestrian.cfg\"):\n",
    "    \"\"\"\n",
    "    :param output_dir: the path of output video\n",
    "    :param output_vid: the path of output bird's eye view video\n",
    "    :param video_path: the path of input video\n",
    "    :param weights_path: Yolov3 weights path\n",
    "    :param config_path: Yolov3 config path\n",
    "    :return:\n",
    "    \"\"\"\n",
    "    \n",
    "    global mouse_pts\n",
    "    mouse_pts = []\n",
    "    net_yl = cv2.dnn.readNetFromDarknet(config_path, weights_path)\n",
    "    ln = net_yl.getLayerNames()\n",
    "    ln1 = [ln[i[0] - 1] for i in net_yl.getUnconnectedOutLayers()]\n",
    "\n",
    "    cv2.namedWindow(\"Draw a rectangle and 3 points in real life coordinates\")\n",
    "    cv2.setMouseCallback(\"Draw a rectangle and 3 points in real life coordinates\", get_mouse_points)\n",
    "    np.random.seed(62)\n",
    "\n",
    "    calculate_social_distancing(video_path, net_yl, output_dir, ln1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "confid = 0.05\n",
    "thresh = 0.1\n",
    "mouse_pts = []\n",
    "main(video_path=\"data/example2.mp4\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "name": "social.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
